{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, classification_report\n",
    "#from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "import missingno as msno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Load Dataset\n",
    "df = pd.read_csv('./water_potability.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df ['Solids'] = df['Solids']/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Profile Report\n",
    " \n",
    "#Importing package\n",
    "import pandas_profiling as pp\n",
    "from IPython.display import IFrame\n",
    " \n",
    "#Profile Report\n",
    "DataReport = pp.ProfileReport(df)\n",
    "DataReport.to_file('WaterReport.html')\n",
    "display(IFrame('WaterReport.html', width=900, height=350))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPLORATORY DATA ANALYSIS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overview of Dataset Characteristics\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistics of the dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Potability').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "describeNum = df.describe(include =['float64', 'int64', 'float', 'int'])\n",
    "describeNum.T.style.background_gradient(cmap='viridis',low=0.2,high=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors=['#f94144', '#48cae4']\n",
    "labels=['Not Potable','Potable']\n",
    "pieplot = df.groupby('Potability').size()\n",
    "pieplot.plot(kind='pie', colors=colors, subplots=True,shadow=True, figsize=(7, 7), fontsize=9, autopct='%1.1f%%')\n",
    "plt.title(\"Potability Values Distribution\")\n",
    "plt.legend(labels)\n",
    "plt.ylabel(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogram of numeric variables\n",
    "num_bins = 10\n",
    "\n",
    "df.hist(bins=num_bins, figsize=(20,15))\n",
    "plt.savefig(\"water_histogram_plots\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Skewness \n",
    "\n",
    "plt.style.use('seaborn-dark')\n",
    "colors=['#00a8e8', '#00afb9',  '#48bfe3', '#006e90', '#20a4f3', '#00b4d8', '#0466c8', '#20a4f3', '#00008B','#1E90FF']\n",
    "i=0\n",
    "while i<10:\n",
    "    for col in df.columns:\n",
    "        plt.figure(figsize=(6,4))\n",
    "        sns.distplot(df[col],color=colors[i])\n",
    "        plt.title(f'Distribution plot for {col}')\n",
    "        plt.xlabel(f'Skewness = {round(df[col].skew(),3)}',fontsize=14)\n",
    "        i+=1\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "for i, column in enumerate(df.columns[:9]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    sns.histplot(df[column],kde=True,alpha=0.3, bins=10, color='blue',common_norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.skew().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bivariate Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data = df, x = 'Potability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Most features are normal distribution. Values between 0.5 to -0.5 will be considered as the normal distribution. Though Solids has value slightly above 0.5, we still consider it doesn't have skewness.\n",
    "\n",
    "sns.pairplot(df, hue ='Potability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Potability and Ph\n",
    "fig,ax  = plt.subplots(figsize = (12,5))\n",
    "sns.boxplot(data =df, x = 'ph', y = 'Potability', orient = 'h').set(title = 'Ph distribution');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Potability and hardness distribution\n",
    "fig,ax  = plt.subplots(figsize = (12,5))\n",
    "sns.boxplot(data =df, x = 'Hardness', y = 'Potability', orient = 'h').set(title = 'Hardness distribution');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Potability and  Solids distribution\n",
    "fig,ax  = plt.subplots(figsize = (12,5))\n",
    "sns.boxplot(data =df, x = 'Solids', y = 'Potability', orient = 'h').set(title = 'Solids distribution');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Potability and Chloramines distribution\n",
    "fig,ax  = plt.subplots(figsize = (12,5))\n",
    "sns.boxplot(data =df, x = 'Chloramines', y = 'Potability', orient = 'h').set(title = 'Chloramines distribution');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Potability and Sulfate distribution\n",
    "fig,ax  = plt.subplots(figsize = (12,5))\n",
    "sns.boxplot(data =df, x = 'Sulfate', y = 'Potability', orient = 'h').set(title = 'Sulfate distribution');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Potability and Conductivity distribution\n",
    "fig,ax  = plt.subplots(figsize = (12,5))\n",
    "sns.boxplot(data =df, x = 'Conductivity', y = 'Potability', orient = 'h').set(title = 'Conductivity distribution');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Potability and Organic_carbon distribution\n",
    "fig,ax  = plt.subplots(figsize = (12,5))\n",
    "sns.boxplot(data =df, x = 'Organic_carbon', y = 'Potability', orient = 'h').set(title = 'Organic_carbon distribution');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Potability and Trihalomethanes distribution\n",
    "fig,ax  = plt.subplots(figsize = (12,5))\n",
    "sns.boxplot(data =df, x = 'Trihalomethanes', y = 'Potability', orient = 'h').set(title = 'Trihalomethanes distribution');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Potability and Turbidity distribution\n",
    "fig,ax  = plt.subplots(figsize = (12,5))\n",
    "sns.boxplot(data =df, x = 'Turbidity', y = 'Potability', orient = 'h').set(title = 'Turbidity distribution');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap among features\n",
    "\n",
    "fig,ax = plt.subplots(figsize = (10,7))\n",
    "sns.heatmap(df.corr(),annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation with Potability\n",
    "plt.figure(figsize=(7, 10))\n",
    "heatmap = sns.heatmap(df.corr()[['Potability']].sort_values(by='Potability', ascending=False),annot=True, cmap='GnBu_r')\n",
    "plt.title('Descending Correlation with Potability',pad=20, fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HANDLING OUTLIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#outliers in the data.\n",
    "\n",
    "i=1\n",
    "plt.figure(figsize=(15,25))\n",
    "for feature in df.columns:\n",
    "    plt.subplot(6,3,i)\n",
    "    sns.boxplot(y=df[feature])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing outliers\n",
    "\n",
    "cols = ['ph', 'Hardness', 'Solids', 'Chloramines', 'Sulfate', 'Conductivity',\n",
    "       'Organic_carbon', 'Trihalomethanes', 'Turbidity', 'Potability'] # one or more\n",
    "\n",
    "Q1 = df[cols].quantile(0.25)\n",
    "Q3 = df[cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "df = df[~((df[cols] < (Q1 - 1.5 * IQR)) |(df[cols] > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "print(\"Old Shape: \", df1.shape)\n",
    "print(\"New Shape: \", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outliers in the data.\n",
    "\n",
    "i=1\n",
    "plt.figure(figsize=(15,25))\n",
    "for feature in df1.columns:\n",
    "    plt.subplot(6,3,i)\n",
    "    sns.boxplot(y=df1[feature])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outliers in the data.\n",
    "\n",
    "i=1\n",
    "plt.figure(figsize=(15,25))\n",
    "for feature in df.columns:\n",
    "    plt.subplot(6,3,i)\n",
    "    sns.boxplot(y=df[feature])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DUPLICATE VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NULL VALUES - PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Summary of N/A Values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.bar(df, figsize = (16,5),color = \"#483D8B\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the number and percentage of missing data points per column\n",
    "null=pd.DataFrame(df.isnull().sum(),columns=[\"Null Values\"])\n",
    "null[\"% Missing Values\"]=(df.isna().sum()/len(df)*100)\n",
    "null = null[null[\"% Missing Values\"] > 0]\n",
    "null.style.background_gradient(cmap='viridis',low =0.2,high=0.1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The missing values are columns - \n",
    "\n",
    "'ph', 14.98%  \n",
    "'sulfate', 23.84%  \n",
    "'Trihalomethanes', 4.94%\n",
    "\n",
    "It might not be a good idea to drop all the missing value columns. \n",
    "Let's continue exploring the dataset and then deal with these missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between mean and median values of potable water is also small.\n",
    "\n",
    "ph: 7.0367 (median) 7.0737 (mean)\n",
    "Sulfate: 331.8381 (median) 332.5670 (mean)\n",
    "Trihalomethanes: 66.6782 (median) 66.5397 (mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FILL THE GAP IN DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can use the overall median of the feature to impute values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ph'].fillna(value=df['ph'].median(), inplace=True)\n",
    "df['Sulfate'].fillna(value=df['Sulfate'].median(), inplace=True)\n",
    "df['Trihalomethanes'].fillna(value=df['Trihalomethanes'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The first step is to scale the data. \n",
    "#This is important because scaling can ensure that one factor will not impact the model just because of their large magnitude.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = df.drop('Potability', axis =1)\n",
    "y = df['Potability']\n",
    "features = X.columns\n",
    "X[features] = sc.fit_transform(X[features])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# assign 20% for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "DeTree = DecisionTreeClassifier(max_depth = 4, random_state = 42, min_samples_leaf = 1, criterion ='entropy')\n",
    "# model training\n",
    "DeTree.fit(X_train, y_train)\n",
    "# prediction\n",
    "DeTree_pred = DeTree.predict(X_test)\n",
    "# accuracy\n",
    "DeTree_acc = accuracy_score(y_test, DeTree_pred)\n",
    "# precision\n",
    "DeTree_prec = precision_score(y_test, DeTree_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The accuracy for Decision Tree is\", DeTree_acc)\n",
    "print(\"The classification report using Decision Tree is:\")\n",
    "print(classification_report(y_test, DeTree_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot confusion matrix\n",
    "DeTree_cm = confusion_matrix(y_test, DeTree_pred)\n",
    "sns.heatmap(DeTree_cm/np.sum(DeTree_cm), annot = True, fmt = '0.2%', cmap = 'Blues')\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class')\n",
    "plt.title('Decision Tree')\n",
    "plt.savefig('Decision Tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix for Decision Tree\n",
    "DeTree_cm = confusion_matrix(y_test, DeTree_pred)\n",
    "sns.heatmap(DeTree_cm, annot=True, fmt='.2f')\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class')\n",
    "plt.title('Decision Tree')\n",
    "plt.savefig('Decision Tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "RmTree = RandomForestClassifier(n_estimators =100,min_samples_leaf =2, random_state = 42)\n",
    "# model training\n",
    "RmTree.fit(X_train, y_train)\n",
    "# prediction\n",
    "RmTree_pred = RmTree.predict(X_test)\n",
    "# accuracy\n",
    "RmTree_acc = accuracy_score(y_test, RmTree_pred)\n",
    "# precision\n",
    "RmTree_prec = precision_score(y_test, RmTree_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The accuracy for Random Forest is\", RmTree_acc)\n",
    "print(\"The classification report using Random Forest is:\")\n",
    "print(classification_report(y_test, RmTree_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot confusion matrix\n",
    "RmTree_cm = confusion_matrix(y_test, RmTree_pred)\n",
    "#RmTree_cm\n",
    "sns.heatmap(RmTree_cm/np.sum(RmTree_cm), annot = True, fmt = '0.2%', cmap = 'Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix for Random Forest\n",
    "DeTree_cm = confusion_matrix(y_test, RmTree_pred)\n",
    "sns.heatmap(RmTree_cm, annot=True, fmt='.2f')\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class')\n",
    "plt.title('Random Forest')\n",
    "plt.savefig('Random Forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "LogReg = LogisticRegression(random_state = 42)\n",
    "# model training\n",
    "LogReg.fit(X_train, y_train)\n",
    "# prediction\n",
    "LogReg_pred = LogReg.predict(X_test)\n",
    "# accuracy\n",
    "LogReg_acc = accuracy_score(y_test, LogReg_pred)\n",
    "# precision\n",
    "LogReg_prec = precision_score(y_test, LogReg_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The accuracy for Logistic Regression is\", LogReg_acc)\n",
    "print(\"The classification report using Logistic Regression is:\")\n",
    "print(classification_report(y_test, LogReg_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot confusion matrix\n",
    "LogReg_cm = confusion_matrix(y_test, LogReg_pred)\n",
    "sns.heatmap(LogReg_cm/np.sum(LogReg_cm), annot = True, fmt = '0.2%', cmap = 'Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix for Logistic Regression\n",
    "DeTree_cm = confusion_matrix(y_test, LogReg_pred)\n",
    "sns.heatmap(LogReg_cm, annot=True, fmt='.2f')\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class')\n",
    "plt.title('Logistic Regression')\n",
    "plt.savefig('Logistic Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "XGB = XGBClassifier(max_depth= 8, n_estimators= 250, random_state= 0,  learning_rate= 0.03, n_jobs=5)\n",
    "# model training\n",
    "XGB.fit(X_train, y_train)\n",
    "# prediction\n",
    "XGB_pred = XGB.predict(X_test)\n",
    "# accuracy\n",
    "XGB_acc = accuracy_score(y_test, XGB_pred)\n",
    "# precision\n",
    "XGB_prec = precision_score(y_test, XGB_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"The accuracy for XGBoost is\", XGB_acc)\n",
    "print(\"The classification report using XGBoost is:\", XGB_acc)\n",
    "print(classification_report(y_test, XGB_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot confusion matrix\n",
    "XGB_cm = confusion_matrix(y_test, XGB_pred)\n",
    "sns.heatmap(XGB_cm/np.sum(XGB_cm), annot = True, fmt = '0.2%', cmap = 'Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix for XGB\n",
    "DeTree_cm = confusion_matrix(y_test, XGB_pred)\n",
    "sns.heatmap(XGB_cm, annot=True, fmt='.2f')\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class')\n",
    "plt.title('XGB')\n",
    "plt.savefig('XGB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "KNN = KNeighborsClassifier(n_neighbors = 8, leaf_size =20)\n",
    "# model training\n",
    "KNN.fit(X_train, y_train)\n",
    "# prediction\n",
    "KNN_pred = KNN.predict(X_test)\n",
    "# accuracy\n",
    "KNN_acc = accuracy_score(y_test, KNN_pred)\n",
    "# precision\n",
    "KNN_prec = precision_score(y_test, KNN_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The accuracy for KNeighbors is\", KNN_acc)\n",
    "print(\"The classification report using KNeighbors is:\", KNN_acc)\n",
    "print(classification_report(y_test, KNN_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot confusion matrix\n",
    "KNN_cm = confusion_matrix(y_test, KNN_pred)\n",
    "sns.heatmap(KNN_cm/np.sum(KNN_cm), annot = True, fmt = '0.2%', cmap = 'Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix for KNN\n",
    "DeTree_cm = confusion_matrix(y_test, KNN_pred)\n",
    "sns.heatmap(KNN_cm, annot=True, fmt='.2f')\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class')\n",
    "plt.title('KNN')\n",
    "plt.savefig('KNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "SVM = SVC(kernel ='rbf', random_state = 42)\n",
    "# model training\n",
    "SVM.fit(X_train, y_train)\n",
    "# prediction\n",
    "SVM_pred = SVM.predict(X_test)\n",
    "# accuracy\n",
    "SVM_acc = accuracy_score(y_test, SVM_pred)\n",
    "print(\"The accuracy for SVM is\", SVM_acc)\n",
    "print(\"The classification report using SVM is:\", SVM_acc)\n",
    "print(classification_report(y_test, SVM_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The accuracy for SVM is\", SVM_acc)\n",
    "print(\"The classification report using SVM is:\", SVM_acc)\n",
    "print(classification_report(y_test, SVM_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot confusion matrix\n",
    "SVM_cm = confusion_matrix(y_test, SVM_pred)\n",
    "sns.heatmap(SVC_cm/np.sum(SVM_cm), annot = True, fmt = '0.2%', cmap = 'Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix for SVM\n",
    "DeTree_cm = confusion_matrix(y_test, SVM_pred)\n",
    "sns.heatmap(SVM_cm, annot=True, fmt='.2f')\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class')\n",
    "plt.title('SVM')\n",
    "plt.savefig('SVM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "AdaBoost = AdaBoostClassifier(learning_rate = 0.08, n_estimators = 200, random_state = 42)\n",
    "# model training\n",
    "AdaBoost.fit(X_train, y_train)\n",
    "# prediction\n",
    "AdaBoost_pred = AdaBoost.predict(X_test)\n",
    "# accuracy\n",
    "AdaBoost_acc = accuracy_score(y_test, AdaBoost_pred)\n",
    "# precision\n",
    "AdaBoost_prec = precision_score(y_test, AdaBoost_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The accuracy for AdaBoost is\", AdaBoost_acc)\n",
    "print(\"The classification report using AdaBoost is:\", AdaBoost_acc)\n",
    "print(classification_report(y_test, AdaBoost_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot confusion matrix\n",
    "AdaBoost_cm = confusion_matrix(y_test, AdaBoost_pred)\n",
    "sns.heatmap(SVM_cm/np.sum(SVM_cm), annot = True, fmt = '0.2%', cmap = 'Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix for AdaBoost\n",
    "AdaBoost_cm = confusion_matrix(y_test, AdaBoost_pred)\n",
    "sns.heatmap(AdaBoost_cm, annot=True, fmt='.2f')\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class')\n",
    "plt.title('AdaBoost')\n",
    "plt.savefig('AdaBoost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = pd.DataFrame({\n",
    "    'Model':['Logistic Regression', 'Decision Tree', 'Random Forest', 'XGBoost', 'KNeighbours', 'SVM', 'AdaBoost'],\n",
    "    'Accuracy' :[LogReg_acc, DeTree_acc, RmTree_acc, XGB_acc, KNN_acc, SVM_acc, AdaBoost_acc]\n",
    "})\n",
    "models.sort_values(by='Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models1 = pd.DataFrame({\n",
    "    'Model':['Logistic Regression', 'Decision Tree', 'Random Forest', 'XGBoost', 'KNeighbours', 'SVM', 'AdaBoost'],\n",
    "    'Precision' :[LogReg_prec, DeTree_prec, RmTree_prec, XGB_prec, KNN_prec, SVM_prec, AdaBoost_prec]\n",
    "})\n",
    "models1.sort_values(by='Precision', ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(x='Model', y='Accuracy', data = models, \n",
    "            order = models.sort_values(\"Accuracy\").Model,\n",
    "           palette = 'Blues_d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(x='Model', y='Precision', data = models1, \n",
    "            order = models1.sort_values(\"Precision\").Model,\n",
    "           palette = 'Blues_d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up plotting area\n",
    "plt.figure(0).clf()\n",
    "\n",
    "#fit logistic regression model and plot ROC curve\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_pred)\n",
    "auc = round(metrics.roc_auc_score(y_test, y_pred), 4)\n",
    "plt.plot(fpr,tpr,label=\"Logistic Regression, AUC=\"+str(auc))\n",
    "\n",
    "#fit AdaBoostClassifier model and plot ROC curve\n",
    "model = AdaBoostClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_pred)\n",
    "auc = round(metrics.roc_auc_score(y_test, y_pred), 4)\n",
    "plt.plot(fpr,tpr,label=\"AdaBoostClassifier, AUC=\"+str(auc))\n",
    "\n",
    "#fit DecisionTreeClassifier model and plot ROC curve\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_pred)\n",
    "auc = round(metrics.roc_auc_score(y_test, y_pred), 4)\n",
    "plt.plot(fpr,tpr,label=\"DecisionTreeClassifier, AUC=\"+str(auc))\n",
    "\n",
    "\n",
    "#fit KNeighborsClassifier model and plot ROC curve\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_pred)\n",
    "auc = round(metrics.roc_auc_score(y_test, y_pred), 4)\n",
    "plt.plot(fpr,tpr,label=\"KNeighborsClassifier, AUC=\"+str(auc))\n",
    "\n",
    "#fit XGBClassifier model and plot ROC curve\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_pred)\n",
    "auc = round(metrics.roc_auc_score(y_test, y_pred), 4)\n",
    "plt.plot(fpr,tpr,label=\"XGBClassifier, AUC=\"+str(auc))\n",
    "\n",
    "#fit Random Forest model and plot ROC curve\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_pred)\n",
    "auc = round(metrics.roc_auc_score(y_test, y_pred), 4)\n",
    "plt.plot(fpr,tpr,label=\"RandomForestClassifier, AUC=\"+str(auc))\n",
    "\n",
    "#add legend\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up plotting area with SVC\n",
    "plt.figure(0).clf()\n",
    "\n",
    "#fit logistic regression model and plot ROC curve\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_pred)\n",
    "auc = round(metrics.roc_auc_score(y_test, y_pred), 4)\n",
    "plt.plot(fpr,tpr,label=\"Logistic Regression, AUC=\"+str(auc))\n",
    "\n",
    "#fit AdaBoostClassifier model and plot ROC curve\n",
    "model = AdaBoostClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_pred)\n",
    "auc = round(metrics.roc_auc_score(y_test, y_pred), 4)\n",
    "plt.plot(fpr,tpr,label=\"AdaBoostClassifier, AUC=\"+str(auc))\n",
    "\n",
    "#fit DecisionTreeClassifier model and plot ROC curve\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_pred)\n",
    "auc = round(metrics.roc_auc_score(y_test, y_pred), 4)\n",
    "plt.plot(fpr,tpr,label=\"DecisionTreeClassifier, AUC=\"+str(auc))\n",
    "\n",
    "\n",
    "#fit KNeighborsClassifier model and plot ROC curve\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_pred)\n",
    "auc = round(metrics.roc_auc_score(y_test, y_pred), 4)\n",
    "plt.plot(fpr,tpr,label=\"KNeighborsClassifier, AUC=\"+str(auc))\n",
    "\n",
    "#fit XGBClassifier model and plot ROC curve\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_pred)\n",
    "auc = round(metrics.roc_auc_score(y_test, y_pred), 4)\n",
    "plt.plot(fpr,tpr,label=\"XGBClassifier, AUC=\"+str(auc))\n",
    "\n",
    "#fit Random Forest model and plot ROC curve\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_pred)\n",
    "auc = round(metrics.roc_auc_score(y_test, y_pred), 4)\n",
    "plt.plot(fpr,tpr,label=\"RandomForestClassifier, AUC=\"+str(auc))\n",
    "\n",
    "#fit SVC model and plot ROC curve\n",
    "model = SVC()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_pred)\n",
    "auc = round(metrics.roc_auc_score(y_test, y_pred), 4)\n",
    "plt.plot(fpr,tpr,label=\"SVM, AUC=\"+str(auc))\n",
    "\n",
    "#add legend\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
